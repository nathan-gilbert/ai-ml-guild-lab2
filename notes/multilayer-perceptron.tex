\documentclass[letterpaper,12pt]{article}
\usepackage{amssymb,latexsym,amsmath}
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

\begin{document}

\begin{flushleft}
    Perceptrons\\
    AI/ML Guild Lab \#2\\
    \today \\
\end{flushleft}

\section{Multilayer Perceptrons}

It's really a misnomer to call Multilayer Perceptrons \emph{multi-layer}. It's
not a perceptron with multiple layers but instead it is a network of multiple
``neuron-like'' processing units but not every layer in the network is a
perceptron.

Recall that the perceptron equation:

\[
    \phi(x) = \sum_{i=0}^{N} W_i x_i + b
\]

What would happen if you applied multiple layers of this equation?

\section{History}

Dudes named Rumelhart, Hinton, and Williams introduced/discovered this algorithm
in the mid-â€˜80s.

\end{document}

